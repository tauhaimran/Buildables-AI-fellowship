{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f546431",
   "metadata": {},
   "source": [
    "\n",
    "**Tauha Imran** | _Buildables AI Fellowship – Week 2_  \n",
    "\n",
    "[LinkedIn](https://www.linkedin.com/in/tauha-imran-6185b3280/) · [GitHub](https://github.com/tauhaimran) · [Portfolio](https://tauhaimran.github.io/)  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa8f49",
   "metadata": {},
   "source": [
    "### Assignment 1: LLM Understanding\n",
    "\n",
    "* Write a short note (3–4 sentences) explaining the difference between **encoder-only, decoder-only, and encoder-decoder LLMs**.\n",
    "\n",
    "Encoder-only models focus on understanding input text by creating contextual embeddings (good for classification or sentiment analysis).\n",
    "Decoder-only models generate text autoregressively, predicting the next token (good for text completion or chatbots).\n",
    "Encoder-decoder models first encode input into a representation, then decode it into output (good for translation or summarization).\n",
    "\n",
    "Example usage:\n",
    "\n",
    "Encoder-only: BERT → Sentiment analysis\n",
    "\n",
    "Decoder-only: GPT-3 → Story generation\n",
    "\n",
    "Encoder-decoder: T5 → Text summarization\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63222cd6",
   "metadata": {},
   "source": [
    "### Assignment 2: STT/TTS Exploration\n",
    "\n",
    "* Find **one STT model** and **one TTS model** (other than Whisper/Google).\n",
    "* Write down:\n",
    "  * What it does.\n",
    "  * One possible application.\n",
    "\n",
    "STT Model: DeepSpeech (Mozilla)\n",
    "\n",
    "What it does: Converts spoken audio into written text using RNN-based acoustic and language models.\n",
    "\n",
    "Application: Transcribing lectures or meetings into text.\n",
    "\n",
    "TTS Model: Tacotron 2 (Google)\n",
    "\n",
    "What it does: Generates natural-sounding speech from text by combining a sequence-to-sequence model with a vocoder.\n",
    "\n",
    "Application: Creating realistic voice assistants or audiobook narration.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d43cc5",
   "metadata": {},
   "source": [
    "###  Assignment 3: Build a Chatbot with Memory\n",
    "\n",
    "* Write a Python program that:\n",
    "\n",
    "  * Takes user input in a loop.\n",
    "  * Sends it to Groq API.\n",
    "  * Stores the last 5 messages in memory.\n",
    "  * Ends when user types `\"quit\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e248a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type \"quit\" to exit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# basic chatbot with memmory\n",
    "import os\n",
    "from collections import deque\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "\n",
    "#loading environment variable\n",
    "load_dotenv()\n",
    "\n",
    "#getting & verifiying the key\n",
    "if not os.getenv(\"GROQ_API_KEY\"):\n",
    "    raise RuntimeError( \"GROQ API KEY NOT FOUND - plz check .env configuration\")\n",
    "else:\n",
    "    GROP_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "    #print(GROP_API_KEY)\n",
    "\n",
    "#loading model and prompt\n",
    "MODEL = \"llama-3.3-70b-versatile\"\n",
    "SYSTEM_PROMPT = \"You are a concise, helpful assistant.\"\n",
    "\n",
    "def chatbot():\n",
    "    client = Groq() #creating a groq client\n",
    "    memory = deque(maxlen=5) # to store last 5 mssgs\n",
    "\n",
    "\n",
    "    print(\"Type \\\"quit\\\" to exit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Your Mssg: \").strip()\n",
    "\n",
    "        if user_input.lower() == \"quit\":\n",
    "            print(\"you : 'quit' \")\n",
    "            print(\"groq: bye bye\")\n",
    "            print(\"-------------------------------------------\\n\\n\")\n",
    "            break\n",
    "\n",
    "        #appending to memory - user-input\n",
    "        memory.append({\"role\": \"user\" ,  \"content\" : user_input})\n",
    "        # construct context: system + rolling memory\n",
    "        messages = [ {\"role\": \"user\" ,  \"content\" : SYSTEM_PROMPT}] + list(memory)\n",
    "\n",
    "        try:\n",
    "            resp = client.chat.completions.create( model=MODEL,messages=messages)\n",
    "            assistant_text = resp.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            assistant_text = f\"(Error calling Groq API: {e})\"\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"You: {user_input}\\n\")\n",
    "        print(f\"Bot: {assistant_text}\\n\")\n",
    "        print(\"-------------------------------------------\\n\\n\")\n",
    "\n",
    "        # push assistant reply into memory\n",
    "        memory.append({\"role\": \"assistant\", \"content\": assistant_text})\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "#TESTING THIS CHATBOT\n",
    "chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d72307",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b63491",
   "metadata": {},
   "source": [
    "### Assignment 4: Preprocessing Function\n",
    "\n",
    "* Write a function to clean user input:\n",
    "\n",
    "  * Lowercase text.\n",
    "  * Remove punctuation.\n",
    "  * Strip extra spaces.\n",
    "\n",
    "Test with: `\"  HELLo!!!  How ARE you?? \"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7becc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello how are you\n"
     ]
    }
   ],
   "source": [
    "# file: preprocess_basic.py\n",
    "import re\n",
    "\n",
    "def simple_clean(text: str) -> str:\n",
    "    # 1) lowercase\n",
    "    text = text.lower()\n",
    "    # 2) remove punctuation (keep letters, digits, whitespace)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    # 3) collapse multiple spaces + strip ends\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    s = \"  HELLo!!!  How ARE you?? \"\n",
    "    print(simple_clean(s))  # -> \"hello how are you\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232647bd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0308913a",
   "metadata": {},
   "source": [
    "### Assignment 5: Text Preprocessing\n",
    "\n",
    "* Write a function that:\n",
    "\n",
    "    * Converts text to lowercase.\n",
    "    * Removes punctuation & numbers.\n",
    "    * Removes stopwords (`the, is, and...`).\n",
    "    * Applies stemming or lemmatization.\n",
    "    * Removes words shorter than 3 characters.\n",
    "    * Keeps only nouns, verbs, and adjectives (using POS tagging).\n",
    "\n",
    "pip install spacy\n",
    "python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96f4793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: preprocess_advanced.py\n",
    "from typing import List\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# load once (small English model provides POS + lemmas)\n",
    "_nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "_ALLOWED_POS = {\"NOUN\", \"VERB\", \"ADJ\"}\n",
    "\n",
    "def preprocess_text_spacy(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Returns a list of cleaned tokens after:\n",
    "      - lowercasing\n",
    "      - removing punctuation & numbers\n",
    "      - removing stopwords\n",
    "      - lemmatizing\n",
    "      - removing tokens shorter than 3 chars\n",
    "      - keeping only nouns, verbs, adjectives\n",
    "    \"\"\"\n",
    "    # lowercase early (helps consistency)\n",
    "    doc = _nlp(text.lower())\n",
    "\n",
    "    cleaned = []\n",
    "    for tok in doc:\n",
    "        # keep only alphabetic tokens (no punctuation/numbers)\n",
    "        if not tok.is_alpha:\n",
    "            continue\n",
    "\n",
    "        # pos filter\n",
    "        if tok.pos_ not in _ALLOWED_POS:\n",
    "            continue\n",
    "\n",
    "        lemma = tok.lemma_.lower()\n",
    "\n",
    "        # remove stopwords\n",
    "        if lemma in STOP_WORDS:\n",
    "            continue\n",
    "\n",
    "        # min length\n",
    "        if len(lemma) < 3:\n",
    "            continue\n",
    "\n",
    "        cleaned.append(lemma)\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "#--------------------------------------\n",
    "\n",
    "#TESTING\n",
    "sample = \"AI-driven systems are transforming 2025 industries rapidly!!!\"\n",
    "print(preprocess_text_spacy(sample))\n",
    "# Example output: ['ai', 'drive', 'system', 'transform', 'industry', 'rapid']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
