{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb94534",
   "metadata": {},
   "source": [
    "**Tauha Imran** | _Buildables AI Fellowship – Week 6_  \n",
    "\n",
    "[LinkedIn](https://www.linkedin.com/in/tauha-imran-6185b3280/) · [GitHub](https://github.com/tauhaimran) · [Portfolio](https://tauhaimran.github.io/)  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac356886",
   "metadata": {},
   "source": [
    "### Installing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0436fd6",
   "metadata": {},
   "source": [
    "* **`langchain`** – Core framework to build LLM-powered applications.\n",
    "* **`langchain-community`** – Extra integrations like tools, APIs, and vector stores.\n",
    "* **`langchain-pinecone`** – Connects LangChain with Pinecone for vector storage and retrieval.\n",
    "* **`langchain_groq`** – Enables LangChain to use Groq's ultra-fast language models.\n",
    "* **`datasets`** – Provides ready-to-use NLP/ML datasets from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65db921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.3.23 langchain-community==0.3.21 langchain-pinecone==0.2.5 langchain_groq datasets==3.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b00464f",
   "metadata": {},
   "source": [
    "#### Loading my API Keys from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e6bb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pinecone API Key Loaded Successfully\n",
      "✅ Groq API Key Loaded Successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the keys\n",
    "pinecone_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "groq_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Check if keys are loaded properly\n",
    "if pinecone_key:\n",
    "    print(\"✅ Pinecone API Key Loaded Successfully\")\n",
    "    #print(f\"Pinecone API Key: {pinecone_key}\")\n",
    "else:\n",
    "    print(\"❌ Pinecone API Key NOT Loaded\")\n",
    "\n",
    "if groq_key:\n",
    "    print(\"✅ Groq API Key Loaded Successfully\")\n",
    "    #print(f\"Groq API Key: {groq_key}\")\n",
    "else:\n",
    "    print(\"❌ Groq API Key NOT Loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef1c075",
   "metadata": {},
   "source": [
    "langchain_groq is a LangChain integration that connects to Groq’s fast LLMs like LLaMA3, and ChatGroq is the class that makes it easy to send prompts, get responses, and use these models within LangChain apps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "990bfc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chat = ChatGroq(\n",
    "    groq_api_key=groq_key,\n",
    "    model_name=\"llama-3.3-70b-versatile\"  # Correct model name used by Groq\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21b712",
   "metadata": {},
   "source": [
    "The format is very similar, we're just swapped the role of `\"user\"` for `HumanMessage`, and the role of `\"assistant\"` for `AIMessage`.\n",
    "\n",
    "Then you pass them to the model:\n",
    "\n",
    "```\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8254e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aab48e",
   "metadata": {},
   "source": [
    "We generate the next response from the AI by passing these messages to the `ChatGroq` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912ddade",
   "metadata": {},
   "source": [
    "Like saying to the AI:\n",
    "\n",
    "“Here’s what has been said so far — now tell me what the AI should say next.”\n",
    "\n",
    "LangChain then handles formatting and sending this to the LLM backend, and res stores the AI’s next reply.\n",
    "\n",
    "**In Short:**\n",
    "* You define a conversation (via messages).\n",
    "* Call the LLM using chat(messages).\n",
    "* Get a response back — stored in res."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "109d2008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_32172\\2478578660.py:2: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  res = chat(messages)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    res = chat(messages)\n",
    "except Exception as e:\n",
    "    # print full error so you can see if it's a deprecation/model error\n",
    "    print(\"Model request failed:\", e)\n",
    "    # Optionally re-raise or handle fallback logic here\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d420165f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='String theory! It\\'s a fascinating and complex topic in the realm of theoretical physics. I\\'ll try to break it down in a simplified way.\\n\\n**What is string theory?**\\n\\nString theory proposes that the fundamental building blocks of the universe are not particles (like electrons and quarks), but tiny, vibrating strings. These strings are thought to be the source of all particles and forces in the universe.\\n\\n**Key concepts:**\\n\\n1. **Strings**: The fundamental objects in string theory are one-dimensional strings, rather than point-like particles. These strings can vibrate at different frequencies, giving rise to various particles.\\n2. **Vibrational modes**: The vibrations of the strings correspond to different energy levels, which in turn give rise to the various particles we observe in the universe, such as electrons, photons, and quarks.\\n3. **Extra dimensions**: String theory requires the existence of extra dimensions beyond the three spatial dimensions (length, width, and height) and one time dimension that we experience in everyday life. These extra dimensions are \"curled up\" or \"compactified\" so tightly that we can\\'t directly observe them.\\n4. **Calabi-Yau manifolds**: The extra dimensions in string theory are thought to be compactified into complex geometric structures called Calabi-Yau manifolds. These manifolds determine the properties of the strings and the resulting particles.\\n5. **Supersymmetry**: String theory often incorporates supersymmetry, which proposes the existence of particles with identical properties to known particles, but with different spin values.\\n\\n**Types of string theory:**\\n\\nThere are five consistent superstring theories, which are known as:\\n\\n1. Type I string theory\\n2. Type II string theory (with two subtypes: IIA and IIB)\\n3. Heterotic string theory (with two subtypes: SO(32) and E8×E8)\\n\\nThese theories differ in the way they describe the behavior of strings and the resulting particles.\\n\\n**Challenges and criticisms:**\\n\\nWhile string theory is an active area of research, it\\'s still a highly speculative and incomplete framework. Some of the challenges and criticisms include:\\n\\n1. **Lack of experimental evidence**: Despite decades of research, there is currently no direct experimental evidence to support string theory.\\n2. **Mathematical complexity**: String theory requires advanced mathematical tools, which can make it difficult to understand and work with.\\n3. **Multiverse problem**: String theory predicts the existence of a vast \"multiverse\" of possible universes, which raises questions about the testability and falsifiability of the theory.\\n\\n**Current status and future directions:**\\n\\nString theory remains an active area of research, with many physicists working to develop and test the theory. Some potential avenues for future research include:\\n\\n1. **Phenomenology**: Developing models that can be tested experimentally, such as those related to particle physics and cosmology.\\n2. **Mathematical developments**: Improving our understanding of the mathematical structures underlying string theory.\\n3. **Alternative approaches**: Exploring alternative theories, such as loop quantum gravity and causal dynamical triangulation, which may provide new insights into the nature of spacetime and the universe.\\n\\nI hope this gives you a good introduction to string theory! Do you have any specific questions or aspects you\\'d like me to expand on?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 677, 'prompt_tokens': 79, 'total_tokens': 756, 'completion_time': 1.489796465, 'prompt_time': 0.003869779, 'queue_time': 0.051927127, 'total_time': 1.493666244}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--602fe48b-a5a6-4d40-a20b-6e8acb162f8b-0', usage_metadata={'input_tokens': 79, 'output_tokens': 677, 'total_tokens': 756})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f108837",
   "metadata": {},
   "source": [
    "To see the models reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "748f8abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String theory! It's a fascinating and complex topic in the realm of theoretical physics. I'll try to break it down in a simplified way.\n",
      "\n",
      "**What is string theory?**\n",
      "\n",
      "String theory proposes that the fundamental building blocks of the universe are not particles (like electrons and quarks), but tiny, vibrating strings. These strings are thought to be the source of all particles and forces in the universe.\n",
      "\n",
      "**Key concepts:**\n",
      "\n",
      "1. **Strings**: The fundamental objects in string theory are one-dimensional strings, rather than point-like particles. These strings can vibrate at different frequencies, giving rise to various particles.\n",
      "2. **Vibrational modes**: The vibrations of the strings correspond to different energy levels, which in turn give rise to the various particles we observe in the universe, such as electrons, photons, and quarks.\n",
      "3. **Extra dimensions**: String theory requires the existence of extra dimensions beyond the three spatial dimensions (length, width, and height) and one time dimension that we experience in everyday life. These extra dimensions are \"curled up\" or \"compactified\" so tightly that we can't directly observe them.\n",
      "4. **Calabi-Yau manifolds**: The extra dimensions in string theory are thought to be compactified into complex geometric structures called Calabi-Yau manifolds. These manifolds determine the properties of the strings and the resulting particles.\n",
      "5. **Supersymmetry**: String theory often incorporates supersymmetry, which proposes the existence of particles with identical properties to known particles, but with different spin values.\n",
      "\n",
      "**Types of string theory:**\n",
      "\n",
      "There are five consistent superstring theories, which are known as:\n",
      "\n",
      "1. Type I string theory\n",
      "2. Type II string theory (with two subtypes: IIA and IIB)\n",
      "3. Heterotic string theory (with two subtypes: SO(32) and E8×E8)\n",
      "\n",
      "These theories differ in the way they describe the behavior of strings and the resulting particles.\n",
      "\n",
      "**Challenges and criticisms:**\n",
      "\n",
      "While string theory is an active area of research, it's still a highly speculative and incomplete framework. Some of the challenges and criticisms include:\n",
      "\n",
      "1. **Lack of experimental evidence**: Despite decades of research, there is currently no direct experimental evidence to support string theory.\n",
      "2. **Mathematical complexity**: String theory requires advanced mathematical tools, which can make it difficult to understand and work with.\n",
      "3. **Multiverse problem**: String theory predicts the existence of a vast \"multiverse\" of possible universes, which raises questions about the testability and falsifiability of the theory.\n",
      "\n",
      "**Current status and future directions:**\n",
      "\n",
      "String theory remains an active area of research, with many physicists working to develop and test the theory. Some potential avenues for future research include:\n",
      "\n",
      "1. **Phenomenology**: Developing models that can be tested experimentally, such as those related to particle physics and cosmology.\n",
      "2. **Mathematical developments**: Improving our understanding of the mathematical structures underlying string theory.\n",
      "3. **Alternative approaches**: Exploring alternative theories, such as loop quantum gravity and causal dynamical triangulation, which may provide new insights into the nature of spacetime and the universe.\n",
      "\n",
      "I hope this gives you a good introduction to string theory! Do you have any specific questions or aspects you'd like me to expand on?\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624d2d69",
   "metadata": {},
   "source": [
    "Because `res` is just another `AIMessage` object, we can append it to `messages`, add another `HumanMessage`, and generate the next response in the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c75ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physicists believe that string theory has the potential to produce a unified theory, also known as a \"theory of everything\" (ToE), for several reasons:\n",
      "\n",
      "1. **Unification of forces**: String theory attempts to unify the fundamental forces of nature, including:\n",
      "\t* Gravity (described by general relativity)\n",
      "\t* Electromagnetism (described by quantum electrodynamics)\n",
      "\t* Strong nuclear force (described by quantum chromodynamics)\n",
      "\t* Weak nuclear force (described by the electroweak theory)\n",
      "\tString theory proposes that these forces are different vibrational modes of the same underlying strings.\n",
      "2. **Consistency with quantum mechanics and general relativity**: String theory is an attempt to reconcile two major areas of physics:\n",
      "\t* Quantum mechanics (which describes the behavior of particles at the atomic and subatomic level)\n",
      "\t* General relativity (which describes the behavior of gravity and the large-scale structure of the universe)\n",
      "\tString theory aims to provide a framework that is consistent with both quantum mechanics and general relativity, which is a major challenge in modern physics.\n",
      "3. **Prediction of particle properties**: String theory predicts the existence of particles with specific properties, such as mass, charge, and spin. These predictions can be tested experimentally, and some of them have already been confirmed.\n",
      "4. **Explanation of fundamental constants**: String theory provides a framework for understanding the fundamental constants of nature, such as the gravitational constant, the speed of light, and the Planck constant. These constants are related to the vibrational modes of the strings and the geometry of the extra dimensions.\n",
      "5. **Potential for a complete theory**: String theory has the potential to provide a complete and consistent theory of the universe, including:\n",
      "\t* A description of the fundamental particles and forces\n",
      "\t* A explanation of the origin and evolution of the universe\n",
      "\t* A understanding of the nature of spacetime and gravity\n",
      "\t* A framework for understanding the behavior of matter and energy at all scales\n",
      "\n",
      "Some of the key features of string theory that make it a promising candidate for a unified theory include:\n",
      "\n",
      "* **Duality**: String theory exhibits various dualities, which are symmetries that relate different aspects of the theory. These dualities provide a way to unify different forces and particles.\n",
      "* **Supersymmetry**: String theory often incorporates supersymmetry, which proposes the existence of particles with identical properties to known particles, but with different spin values. Supersymmetry helps to stabilize the theory and provides a framework for understanding the hierarchy of particle masses.\n",
      "* **Extra dimensions**: The extra dimensions in string theory provide a way to unify the fundamental forces and particles, and to explain the properties of the universe at different scales.\n",
      "\n",
      "While string theory is still a highly speculative and incomplete framework, it has the potential to provide a unified theory that explains many of the fundamental aspects of the universe. However, it's essential to note that the development of a complete and consistent theory of everything is an ongoing challenge, and string theory is just one of the many approaches being explored.\n"
     ]
    }
   ],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"Why do physicists believe it can produce a 'unified theory'?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to chat-gpt\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714c7774",
   "metadata": {},
   "source": [
    "## Dealing with Hallucinations\n",
    "\n",
    "We have our chatbot, but as mentioned — the knowledge of LLMs can be limited. The reason for this is that LLMs learn all they know during training. An LLM essentially compresses the \"world\" as seen in the training data into the internal parameters of the model. We call this knowledge the _parametric knowledge_ of the model.\n",
    "\n",
    "By default, LLMs have no access to the external world.\n",
    "\n",
    "The result of this is very clear when we ask LLMs about more recent information, like about Deepseek R1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d2b6ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physicists believe that string theory has the potential to produce a unified theory, also known as a \"theory of everything\" (ToE), for several reasons:\n",
      "\n",
      "1. **Unification of forces**: String theory attempts to unify the fundamental forces of nature, including:\n",
      "\t* Gravity (described by general relativity)\n",
      "\t* Electromagnetism (described by quantum electrodynamics)\n",
      "\t* Strong nuclear force (described by quantum chromodynamics)\n",
      "\t* Weak nuclear force (described by the electroweak theory)\n",
      "\tString theory proposes that these forces are different vibrational modes of the same underlying strings.\n",
      "2. **Consistency with quantum mechanics and general relativity**: String theory is an attempt to reconcile two major areas of physics:\n",
      "\t* Quantum mechanics (which describes the behavior of particles at the atomic and subatomic level)\n",
      "\t* General relativity (which describes the behavior of gravity and the large-scale structure of the universe)\n",
      "\tString theory aims to provide a framework that is consistent with both quantum mechanics and general relativity, which is a major challenge in modern physics.\n",
      "3. **Prediction of particle properties**: String theory predicts the existence of particles with specific properties, such as mass, charge, and spin. These predictions can be tested experimentally, and some of them have already been confirmed.\n",
      "4. **Explanation of fundamental constants**: String theory provides a framework for understanding the fundamental constants of nature, such as the gravitational constant, the speed of light, and the Planck constant. These constants are related to the vibrational modes of the strings and the geometry of the extra dimensions.\n",
      "5. **Potential for a complete theory**: String theory has the potential to provide a complete and consistent theory of the universe, including:\n",
      "\t* A description of the fundamental particles and forces\n",
      "\t* A explanation of the origin and evolution of the universe\n",
      "\t* A understanding of the nature of spacetime and gravity\n",
      "\t* A framework for understanding the behavior of matter and energy at all scales\n",
      "\n",
      "Some of the key features of string theory that make it a promising candidate for a unified theory include:\n",
      "\n",
      "* **Duality**: String theory exhibits various dualities, which are symmetries that relate different aspects of the theory. These dualities provide a way to unify different forces and particles.\n",
      "* **Supersymmetry**: String theory often incorporates supersymmetry, which proposes the existence of particles with identical properties to known particles, but with different spin values. Supersymmetry helps to stabilize the theory and provides a framework for understanding the hierarchy of particle masses.\n",
      "* **Extra dimensions**: The extra dimensions in string theory provide a way to unify the fundamental forces and particles, and to explain the properties of the universe at different scales.\n",
      "\n",
      "While string theory is still a highly speculative and incomplete framework, it has the potential to provide a unified theory that explains many of the fundamental aspects of the universe. However, it's essential to note that the development of a complete and consistent theory of everything is an ongoing challenge, and string theory is just one of the many approaches being explored.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8794be3e",
   "metadata": {},
   "source": [
    "Our chatbot can no longer help us, it doesn't contain the information we need to answer the question. It was very clear from this answer that the LLM doesn't know the informaiton, but sometimes an LLM may respond like it _does_ know the answer — and this can be very hard to detect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e10521",
   "metadata": {},
   "source": [
    "## Alternate Way : Source Knowledge\n",
    "\n",
    "There is another way of feeding knowledge into LLMs. It is called _source knowledge_ and it refers to any information fed into the LLM via the prompt. We can try that with the Deepseek question. We can take the paper abstract from the [Deepseek R1 paper](https://arxiv.org/abs/2501.12948)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9af49e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_knowledge = (\n",
    "    \"We introduce our first-generation reasoning models, DeepSeek-R1-Zero and \"\n",
    "    \"DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale \"\n",
    "    \"reinforcement learning (RL) without supervised fine-tuning (SFT) as a \"\n",
    "    \"preliminary step, demonstrates remarkable reasoning capabilities. Through \"\n",
    "    \"RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and \"\n",
    "    \"intriguing reasoning behaviors. However, it encounters challenges such as \"\n",
    "    \"poor readability, and language mixing. To address these issues and \"\n",
    "    \"further enhance reasoning performance, we introduce DeepSeek-R1, which \"\n",
    "    \"incorporates multi-stage training and cold-start data before RL. \"\n",
    "    \"DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on \"\n",
    "    \"reasoning tasks. To support the research community, we open-source \"\n",
    "    \"DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, \"\n",
    "    \"32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeffaa08",
   "metadata": {},
   "source": [
    "We can feed this additional knowledge into our prompt with some instructions telling the LLM how we'd like it to use this information alongside our original query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40297f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is so special about Deepseek R1?\"\n",
    "\n",
    "augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "Contexts:\n",
    "{source_knowledge}\n",
    "\n",
    "Query: {query}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf6bb0",
   "metadata": {},
   "source": [
    "Now we feed this into our chatbot as we were before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=augmented_prompt\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the context, DeepSeek-R1 is special because it achieves performance comparable to OpenAI-o1-1217 on reasoning tasks, thanks to its multi-stage training and incorporation of cold-start data before reinforcement learning (RL). This suggests that DeepSeek-R1 has advanced reasoning capabilities, making it a notable model in the field. Additionally, the fact that its predecessor, DeepSeek-R1-Zero, was able to demonstrate remarkable reasoning capabilities without supervised fine-tuning (SFT) is also a significant achievement, and DeepSeek-R1 builds upon this foundation to further enhance its performance.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b235b09",
   "metadata": {},
   "source": [
    "## How do we get this information in the first place?\n",
    "\n",
    "The quality of this answer is phenomenal. This is made possible thanks to the idea of augmented our query with external knowledge (source knowledge). There's just one problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b79b1",
   "metadata": {},
   "source": [
    "This is where Pinecone and vector databases comes in place, as they can help us here too. But first, we'll need a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b633b59",
   "metadata": {},
   "source": [
    "## Importing the Data\n",
    "\n",
    "In this task, we will be importing our data. We will be using the Hugging Face Datasets library to load our data. Specifically, we will be using the `\"jamescalam/deepseek-r1-paper-chunked\"` dataset. This dataset contains the Deepseek R1 paper pre-processed into RAG-ready chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['doi', 'chunk-id', 'chunk', 'num_tokens', 'pages', 'source'],\n",
       "    num_rows: 76\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"jamescalam/deepseek-r1-paper-chunked\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c9178a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doi': '2501.12948v1',\n",
       " 'chunk-id': 1,\n",
       " 'chunk': \"uestion: If a > 1, then the sum of the real solutions of √a - √a + x = x is equal to Response: <think> To solve the equation √a – √a + x = x, let's start by squaring both . . . (√a-√a+x)² = x² ⇒ a - √a + x = x². Rearrange to isolate the inner square root term:(a – x²)² = a + x ⇒ a² – 2ax² + (x²)² = a + x ⇒ x⁴ - 2ax² - x + (a² – a) = 0\",\n",
       " 'num_tokens': 145,\n",
       " 'pages': [1],\n",
       " 'source': 'https://arxiv.org/abs/2501.12948'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d81d343",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "The dataset we are using is sourced from the Deepseek R1 ArXiv papers. Each entry in the dataset represents a \"chunk\" of text from the R1 paper.\n",
    "\n",
    "Because most **L**arge **L**anguage **M**odels (LLMs) only contain knowledge of the world as it was during training, even many of the newest LLMs cannot answer questions about Deepseek R1 — at least not without this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729a0ede",
   "metadata": {},
   "source": [
    "## Building the Knowledge Base\n",
    "\n",
    "We now have a dataset that can serve as our chatbot knowledge base. Our next task is to transform that dataset into the knowledge base that our chatbot can use. To do this we must use an embedding model and vector database.\n",
    "\n",
    "We begin by initializing our Pinecone client, this requires a [free API key](https://app.pinecone.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# initialize client\n",
    "pc = Pinecone(api_key=pinecone_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e78b484",
   "metadata": {},
   "source": [
    "Delete the old one to save the resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4aa6f681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted index rag1\n"
     ]
    }
   ],
   "source": [
    "index_name = \"rag1\"\n",
    "\n",
    "#pc.delete_index(index_name)  # delete old one\n",
    "\n",
    "try:\n",
    "    pc.delete_index(index_name)\n",
    "    print(f\"Deleted index {index_name}\")\n",
    "except Exception as e:\n",
    "    if \"NOT_FOUND\" in str(e) or getattr(e, \"status\", None) == 404:\n",
    "        print(f\"Index {index_name} not found — nothing to delete.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "545e1533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"rag1\",\n",
       "    \"metric\": \"dotproduct\",\n",
       "    \"host\": \"rag1-yosiray.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import ServerlessSpec, CloudProvider, AwsRegion, Metric\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    metric=Metric.DOTPRODUCT,\n",
    "    dimension=384,  # ✅ match your embedding model\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=CloudProvider.AWS,\n",
    "        region=AwsRegion.US_EAST_1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df29057",
   "metadata": {},
   "source": [
    "Our index is now ready but it's empty. It is a vector index, so it needs vectors. As mentioned, to create these vector embeddings we will HuggingFace's `sentence-transformers/all-MiniLM-L6-v2` model — we can access it via LangChain like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd405ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "#had to run this in the cli to ge tthis cell to work\n",
    "#%pip install sentence-transformers\n",
    "\n",
    "#embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# CHANGING STRATEGIES TO GET THIS TO WORK\n",
    "\n",
    "from langchain.embeddings import HuggingFaceHubEmbeddings\n",
    "\n",
    "embed_model = HuggingFaceHubEmbeddings(\n",
    "    repo_id=\"sentence-transformers/all-MiniLM-L6-v2\", \n",
    "    huggingfacehub_api_token=\"YOUR_HF_API_KEY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9229b3d",
   "metadata": {},
   "source": [
    "Using this model we can create embeddings like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5daf97c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InferenceClient' object has no attribute 'post'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceHubEmbeddings\n\u001b[32m     15\u001b[39m texts = [\n\u001b[32m     16\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mthis is the first chunk of text\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mthen another second chunk of text is here\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     18\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m res = \u001b[43membed_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mlen\u001b[39m(res), \u001b[38;5;28mlen\u001b[39m(res[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface_hub.py:115\u001b[39m, in \u001b[36mHuggingFaceHubEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    113\u001b[39m _model_kwargs = \u001b[38;5;28mself\u001b[39m.model_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m#  api doc: https://huggingface.github.io/text-embeddings-inference/#/Text%20Embeddings%20Inference/embed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m responses = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m(\n\u001b[32m    116\u001b[39m     json={\u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m: texts, **_model_kwargs}, task=\u001b[38;5;28mself\u001b[39m.task\n\u001b[32m    117\u001b[39m )\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m json.loads(responses.decode())\n",
      "\u001b[31mAttributeError\u001b[39m: 'InferenceClient' object has no attribute 'post'"
     ]
    }
   ],
   "source": [
    "#texts = [\n",
    " #   'this is the first chunk of text',\n",
    " #   'then another second chunk of text is here'\n",
    "#]\n",
    "\n",
    "#res = embed_model.embed_documents(texts)\n",
    "#len(res), len(res[0])\n",
    "\n",
    "#did a this\n",
    "#pip install huggingface_hub==0.25.2\n",
    "\n",
    "from langchain.embeddings import HuggingFaceHubEmbeddings\n",
    "\n",
    "\n",
    "texts = [\n",
    "    'this is the first chunk of text',\n",
    "    'then another second chunk of text is here'\n",
    "]\n",
    "\n",
    "res = embed_model.embed_documents(texts)\n",
    "len(res), len(res[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ea6f5",
   "metadata": {},
   "source": [
    "From this we get two (aligning to our two chunks of text) CHANGE-dimensional embeddings.\n",
    "\n",
    "We're now ready to embed and index all our our data! We do this by looping through our dataset and embedding and inserting everything in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b28f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm  # for progress bar\n",
    "\n",
    "data = dataset.to_pandas()  # this makes it easier to iterate over the dataset\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    # get batch of data\n",
    "    batch = data.iloc[i:i_end]\n",
    "    # generate unique ids for each chunk\n",
    "    ids = [f\"{x['doi']}-{x['chunk-id']}\" for i, x in batch.iterrows()]\n",
    "    # get text to embed\n",
    "    texts = [x['chunk'] for _, x in batch.iterrows()]\n",
    "    # embed text\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    # get metadata to store in Pinecone\n",
    "    metadata = [\n",
    "        {'text': x['chunk'],\n",
    "         'source': x['source']} for i, x in batch.iterrows()\n",
    "    ]\n",
    "    # add to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e4fa5",
   "metadata": {},
   "source": [
    "We can check that the vector index has been populated using `describe_index_stats` like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56bb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e988a",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86c59e",
   "metadata": {},
   "source": [
    "We've built a fully-fledged knowledge base. Now it's time to link that knowledge base to our chatbot. To do that we'll be diving back into LangChain and reusing our template prompt from earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb42eae",
   "metadata": {},
   "source": [
    "To use LangChain here we need to load the LangChain abstraction for a vector index, called a `vectorstore`. We pass in our vector `index` to initialize the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9846ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "text_field = \"text\"  # the metadata field that contains our text\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index=index,\n",
    "    embedding=embed_model,\n",
    "    text_key=text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799256a3",
   "metadata": {},
   "source": [
    "Using this `vectorstore` we can already query the index and see if we have any relevant information given our question about Llama 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3214e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is so special about Deepseek R1?\"\n",
    "\n",
    "vectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fcb169",
   "metadata": {},
   "source": [
    "We return a lot of text here and it's not that clear what we need or what is relevant. Fortunately, our LLM will be able to parse this information much faster than us. All we need is to link the output from our `vectorstore` to our `chat` chatbot. To do that we can use the same logic as we used earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98c418",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a15337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    # get top 3 results from knowledge base\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    # get the text from the results\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # feed into an augmented prompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "\n",
    "    Query: {query}\"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a526be0",
   "metadata": {},
   "source": [
    "Using this we produce an augmented prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769766aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(augment_prompt(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb59e5e8",
   "metadata": {},
   "source": [
    "There is still a lot of text here, so let's pass it onto our chat model to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a399de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=augment_prompt(query)\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d917fe",
   "metadata": {},
   "source": [
    "We can continue with another Deepseek R1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cadefe45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'augment_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m prompt = HumanMessage(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     content=\u001b[43maugment_prompt\u001b[49m(\n\u001b[32m      3\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhow does deepseek r1 compare to deepseek r1 zero?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m     )\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m res = chat(messages + [prompt])\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(res.content)\n",
      "\u001b[31mNameError\u001b[39m: name 'augment_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=augment_prompt(\n",
    "        \"how does deepseek r1 compare to deepseek r1 zero?\"\n",
    "    )\n",
    ")\n",
    "\n",
    "res = chat(messages + [prompt])\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef84ba",
   "metadata": {},
   "source": [
    "You can continue asking questions about Deepseek R1, but once you're done you can delete the index to save resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.delete_index(index_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
